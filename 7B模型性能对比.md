# 7B vs 14B 模型性能对比

## 📊 实际测试数据

### 推理速度对比

| 指标 | 7B 模型 | 14B 模型 | 提升倍数 |
|------|---------|----------|---------|
| **推理速度** | ~59-63 tokens/s | ~30-34 tokens/s | **~2倍** ⚡ |
| **API响应时间** | ~1.0 秒 | ~5.1 秒 | **~5倍** ⚡ |
| **模型大小** | 4.7 GB | 9.0 GB | **~2倍** 💾 |
| **内存占用** | ~6-8 GB | ~12-16 GB | **~2倍** 💾 |

### 性能测试结果

**7B 模型**:
```
prompt eval rate:     59.03 tokens/s
eval rate:            63.22 tokens/s
API响应:              ~1.0 秒
```

**14B 模型**:
```
prompt eval rate:     30.50 tokens/s
eval rate:            33.82 tokens/s
API响应:              ~5.1 秒
```

## ⏱️ 时间估算对比

### 单个实例处理时间

| 模型 | 预估时间/实例 | 说明 |
|------|-------------|------|
| **7B** | **1.5-3 分钟** | 速度快,但可能需要更多迭代 |
| **14B** | **3-5 分钟** | 更准确,但较慢 |

### 不同规模的时间对比

| 实例数 | 7B 模型 | 14B 模型 | 时间节省 |
|--------|---------|----------|---------|
| **3 个** | **5-9 分钟** | 9-15 分钟 | **~40-50%** |
| **5 个** | **8-15 分钟** | 15-25 分钟 | **~40-50%** |
| **10 个** | **15-30 分钟** | 30-50 分钟 | **~40-50%** |
| **50 个** | **1.5-2.5 小时** | 2.5-4 小时 | **~40-50%** |
| **300 个** (Lite) | **7.5-12 小时** | 15-24 小时 | **~40-50%** |

## 🎯 准确率预估

### 预期性能差异

| 指标 | 7B 模型 | 14B 模型 | 差异 |
|------|---------|----------|------|
| **Resolved Rate** | 5-8% | 8-12% | **-3-4%** |
| **Attempted Rate** | 80-90% | 85-95% | **-5%** |
| **Success Rate** | 6-10% | 10-15% | **-4-5%** |

**注意**: 这些是预估数据,实际结果可能因任务类型而异。

### 准确率 vs 速度权衡

```
7B 模型:
  ✅ 速度: 快 2-3 倍
  ✅ 资源: 内存占用减半
  ⚠️  准确率: 可能低 30-40%

14B 模型:
  ✅ 准确率: 更高
  ⚠️  速度: 较慢
  ⚠️  资源: 需要更多内存
```

## 💡 使用建议

### 场景 1: 快速验证和测试 (推荐 7B)

**适用场景**:
- ✅ 快速验证环境配置
- ✅ 测试脚本和流程
- ✅ 快速迭代和调试
- ✅ 资源受限环境

**推荐配置**:
```bash
./quick_test_7b_5min.sh   # 3个实例, 3-5分钟
./quick_test_7b_10min.sh  # 5个实例, 8-12分钟
```

### 场景 2: 正式评测和对比 (推荐 14B)

**适用场景**:
- ✅ 正式性能评测
- ✅ 提交结果到 Leaderboard
- ✅ 需要最高准确率
- ✅ 有充足时间和资源

**推荐配置**:
```bash
./run_baseline_eval.sh    # 50个实例, 2.5-4小时
./run_optimized_eval.sh   # 50个实例, 4-6小时
```

### 场景 3: 混合策略

**策略**: 先用 7B 快速测试,再用 14B 正式评测

```bash
# 步骤 1: 7B 快速验证 (5-10分钟)
./quick_test_7b_10min.sh

# 步骤 2: 如果通过,运行 14B 正式评测
./run_baseline_eval.sh
```

## 📈 5-10 分钟快速测试对比

### 使用 7B 模型

| 测试时长 | 实例数 | 迭代次数 | 预计时间 |
|---------|--------|---------|---------|
| **5分钟** | **3 个** | 20 | **3-5 分钟** |
| **10分钟** | **5 个** | 25 | **8-12 分钟** |

**优势**:
- ✅ 可以测试更多实例
- ✅ 速度更快
- ✅ 资源占用更少

### 使用 14B 模型

| 测试时长 | 实例数 | 迭代次数 | 预计时间 |
|---------|--------|---------|---------|
| **5分钟** | **2 个** | 15 | **5-7 分钟** |
| **10分钟** | **3 个** | 20 | **8-12 分钟** |

**优势**:
- ✅ 准确率更高
- ✅ 结果更可靠

## 🔧 配置说明

### 7B 模型配置

已在 `config.toml` 中添加:

```toml
[llm.eval_local_model_7b]
model = "ollama/qwen2.5-coder:7b"
base_url = "http://localhost:11434"
api_key = "ollama"
temperature = 0.0
max_input_tokens = 32000
max_output_tokens = 4096
caching_prompt = true
```

### 使用方式

```bash
# 使用 7B 模型
--llm-config eval_local_model_7b

# 使用 14B 模型 (默认)
--llm-config eval_local_model
```

## 📊 完整评测时间对比

### SWE-Bench Lite (300 实例)

| 模型 | 预估时间 | 准确率预估 |
|------|---------|-----------|
| **7B** | **7.5-12 小时** | 5-8% |
| **14B** | **15-24 小时** | 8-12% |

### SWE-Bench Full (2,294 实例)

| 模型 | 预估时间 | 准确率预估 |
|------|---------|-----------|
| **7B** | **57-92 小时** (2.4-3.8 天) | 3-6% |
| **14B** | **115-184 小时** (4.8-7.7 天) | 6-10% |

## ✅ 推荐方案

### 对于 5-10 分钟快速测试

**强烈推荐使用 7B 模型**:

```bash
# 5分钟快速测试 (3个实例)
./quick_test_7b_5min.sh

# 10分钟快速测试 (5个实例)
./quick_test_7b_10min.sh
```

**理由**:
1. ✅ 速度更快 (2-3倍)
2. ✅ 可以测试更多实例
3. ✅ 资源占用更少
4. ✅ 对于快速验证,准确率差异可接受

### 对于正式评测

**推荐使用 14B 模型**:

```bash
# 基线评测
./run_baseline_eval.sh

# 优化评测
./run_optimized_eval.sh
```

**理由**:
1. ✅ 准确率更高
2. ✅ 结果更可靠
3. ✅ 适合提交和对比

## 🎯 总结

### 7B 模型优势

- ⚡ **速度**: 快 2-3 倍
- 💾 **资源**: 内存占用减半
- 🚀 **效率**: 可以测试更多实例

### 7B 模型劣势

- ⚠️ **准确率**: 可能低 30-40%
- ⚠️ **可靠性**: 复杂任务表现较差

### 最佳实践

1. **快速测试**: 使用 7B (5-10分钟)
2. **正式评测**: 使用 14B (完整评测)
3. **资源受限**: 使用 7B
4. **追求准确率**: 使用 14B

---

**更新时间**: 2025-11-22
**基于**: 实际测试数据 (qwen2.5-coder:7b vs 14b)

